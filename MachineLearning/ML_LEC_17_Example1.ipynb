{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (10, 1) , t_data.shape =  (10, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20]).reshape(10,1)\n",
    "t_data = np.array([0, 0, 0, 0,  0,  0,  1,  1,  1,  1]).reshape(10,1)\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape, \", t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.81278093]] , W.shape =  (1, 1) , b =  [0.78628141] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(1,1)\n",
    "    # ì´ê±´ ì–´ë–¤ ì˜ë¯¸ì¸ê°€? 0~1 ì‚¬ì´ì˜ ëœë¤ ê°’ìœ¼ë¡œ êµ¬ì„±ëœ 1x1 í–‰ë ¬ì„ ë¦¬í„´í•˜ë¼ëŠ” ë§. ëœë¤ ê°’ì˜ ë²”ìœ„ëŠ” ì§€ì •í•˜ì§€ ëª»í•˜ë©° dimension ë§Œ ì§€ì • ê°€ëŠ¥í•¨.\n",
    "b = np.random.rand(1)\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ìµœì¢…ì¶œë ¥ì€ y = sigmoid(Wx+b) ì´ë©°, ì†ì‹¤í•¨ìˆ˜ëŠ” cross-entropy ë¡œ ë‚˜íƒ€ëƒ„\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def loss_func(x, t):\n",
    "\n",
    "    delta = 1e-7    # log ë¬´í•œëŒ€ ë°œì‚° ë°©ì§€\n",
    "\n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "\n",
    "    # cross-entropy\n",
    "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "\n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ì†ì‹¤í•¨ìˆ˜ ê°’ ê³„ì‚° í•¨ìˆ˜\n",
    "# ì…ë ¥ë³€ìˆ˜ x, t : numpy type\n",
    "def error_val(x, t):\n",
    "    delta = 1e-7    # log ë¬´í•œëŒ€ ë°œì‚° ë°©ì§€\n",
    "\n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "\n",
    "    # cross-entropy\n",
    "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) )\n",
    "\n",
    "# í•™ìŠµì„ ë§ˆì¹œ í›„, ì„ì˜ì˜ ë°ì´í„°ì— ëŒ€í•´ ë¯¸ë˜ ê°’ ì˜ˆì¸¡ í•¨ìˆ˜\n",
    "# ì…ë ¥ë³€ìˆ˜ x : numpy type\n",
    "def predict(x):\n",
    "\n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "\n",
    "    if y >= 0.5:\n",
    "        result = 1  # True\n",
    "    else:\n",
    "        result = 0  # False\n",
    "\n",
    "    return y, result\n",
    "    # ì¤‘ìš”: true, false ë¿ ì•„ë‹ˆë¼ ì‹¤ì œ sigmoid ê²°ê³¼ ê°’ë„ ì „ë‹¬í•´ ì¤€ë‹¤. ì´ ê°’ì€ ë°œìƒ í™•ë¥ ì´ë¯€ë¡œ ìœ ìš©í•˜ê²Œ ì‚¬ìš©ë  ìˆ˜ ìˆê¸° ë•Œë¬¸."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  38.95745235803363 Initial W =  [[0.81278093]] \n",
      " , b =  [0.78628141]\n",
      "step =  0 error value =  21.379414294328008 W =  [[0.39593939]] , b =  [0.72959828]\n",
      "step =  400 error value =  2.81273658610562 W =  [[0.2779565]] , b =  [-4.10463396]\n",
      "step =  800 error value =  1.7834042009950375 W =  [[0.45343756]] , b =  [-5.6420605]\n",
      "step =  1200 error value =  1.517739952670369 W =  [[0.53076197]] , b =  [-6.67168246]\n",
      "step =  1600 error value =  1.3523020299282267 W =  [[0.59201045]] , b =  [-7.48501423]\n",
      "step =  2000 error value =  1.2358648353317139 W =  [[0.64352097]] , b =  [-8.16753825]\n",
      "step =  2400 error value =  1.1477260443991748 W =  [[0.68841922]] , b =  [-8.7613922]\n",
      "step =  2800 error value =  1.0777104348445983 W =  [[0.72849388]] , b =  [-9.29066818]\n",
      "step =  3200 error value =  1.0201516519119636 W =  [[0.76487193]] , b =  [-9.77052943]\n",
      "step =  3600 error value =  0.9716069844345633 W =  [[0.79831312]] , b =  [-10.21118674]\n",
      "step =  4000 error value =  0.9298455696493776 W =  [[0.82935603]] , b =  [-10.61987024]\n",
      "step =  4400 error value =  0.8933482586813446 W =  [[0.85839755]] , b =  [-11.00190228]\n",
      "step =  4800 error value =  0.861038935711523 W =  [[0.88573935]] , b =  [-11.36132408]\n",
      "step =  5200 error value =  0.8321304340221544 W =  [[0.91161658]] , b =  [-11.70128262]\n",
      "step =  5600 error value =  0.8060313880048443 W =  [[0.93621643]] , b =  [-12.02428055]\n",
      "step =  6000 error value =  0.7822874198302662 W =  [[0.95969054]] , b =  [-12.33234381]\n",
      "step =  6400 error value =  0.7605426239983752 W =  [[0.98216367]] , b =  [-12.62713751]\n",
      "step =  6800 error value =  0.7405135475747404 W =  [[1.00373979]] , b =  [-12.91004838]\n",
      "step =  7200 error value =  0.721971134139975 W =  [[1.02450657]] , b =  [-13.18224466]\n",
      "step =  7600 error value =  0.7047278976364116 W =  [[1.04453865]] , b =  [-13.4447206]\n",
      "step =  8000 error value =  0.6886286219968715 W =  [[1.06390019]] , b =  [-13.69832999]\n",
      "step =  8400 error value =  0.6735434933045651 W =  [[1.08264675]] , b =  [-13.94381202]\n",
      "step =  8800 error value =  0.6593629450594488 W =  [[1.10082683]] , b =  [-14.18181128]\n",
      "step =  9200 error value =  0.6459937322803865 W =  [[1.11848301]] , b =  [-14.4128936]\n",
      "step =  9600 error value =  0.6333559017745184 W =  [[1.13565292]] , b =  [-14.63755864]\n",
      "step =  10000 error value =  0.621380425824406 W =  [[1.15236999]] , b =  [-14.85625005]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2  # ë°œì‚°í•˜ëŠ” ê²½ìš°, 1e-3 ~ 1e-6 ë“±ìœ¼ë¡œ ë°”ê¾¸ì–´ì„œ ì‹¤í–‰\n",
    "\n",
    "f = lambda x : loss_func(x_data,t_data)  # f(x) = loss_func(x_data, t_data)\n",
    "    # ì—¬ê¸°ì„œ ì¤‘ìš”í•œ íŠ¹ì´ ì‚¬í•­ì´ ìˆë‹¤.\n",
    "    # ëŒë‹¤ í•¨ìˆ˜ì˜ ì¸ì xê°€ lambda êµ¬í˜„ ë‚´ì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•Šê³  ìˆë‹¤.\n",
    "    # í•˜ì§€ë§Œ f í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê³³ì˜ ì½”ë“œë¥¼ ë³´ë©´ W ì™€ b ê°€ xë¡œ ì „ë‹¬ì´ ë˜ëŠ”ë°,\n",
    "    # ì´ê²Œ ì „ì—­ ë³€ìˆ˜ì²˜ëŸ¼ ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— ë¬¸ì œ ì—†ì´ ë™ì‘ì€ í•œë‹¤.\n",
    "    # ê·¸ë¦¬ ì¢‹ì€ ë°©ë²•ì€ ì•„ë‹Œ ê²ƒ ê°™ìŒ.\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b )\n",
    "\n",
    "for step in  range(10001):\n",
    "\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "\n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \",b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.12049907e-05]] 0\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ì œ ì…ë ¥ ë°ì´í„°ì— ì—†ëŠ” ê°’ì„ ë„£ì–´ ë³´ì•„ì„œ ì˜ˆìƒëŒ€ë¡œ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸.\n",
    "\n",
    "(real_val, logical_val) = predict(3)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99128572]] 1\n"
     ]
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(17)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=    13.1 [[0.55966359]] 1\n",
      "x=13.00001 [[0.53110263]] 1\n",
      "x=    12.9 [[0.5023307]] 1\n",
      "x=   12.89 [[0.49944979]] 0\n",
      "x=  12.897 [[0.50146643]] 1\n",
      "x=  12.894 [[0.50060216]] 1\n",
      "x=  12.892 [[0.50002597]] 1\n",
      "x=  12.891 [[0.49973788]] 0\n"
     ]
    }
   ],
   "source": [
    "# í™•ë¥ ì´ 50% ì¸ ë¶€ë¶„ì´ ì–´ë””ì¯¤ì¼ê¹Œ?\n",
    "# ì™œ 13 ì´ ì•„ë‹ˆë¼ 13 ë³´ë‹¤ ë” ì ì€ ê°’ì´ ë ê¹Œ?\n",
    "\n",
    "for x in [\n",
    "    13.1, 13.00001, 12.9, 12.89, 12.897, 12.894, 12.892, 12.891,\n",
    "]:\n",
    "    (real_val, logical_val) = predict(x)\n",
    "    print(f'x={x:8}', real_val, logical_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ê¶ê¸ˆí•œ ì :\n",
    "\n",
    "  - $ y = sigmoid(z) = \\dfrac {1} {1+e^{-z}} = \\dfrac {1} {1+e^{-(Wx+b)}} $\n",
    "\n",
    "    - sigmoid í•¨ìˆ˜ì˜ ê²°ê³¼ì¸ yëŠ” ì–´ì°¨í”¼ 0ì˜ ê°’ì„ ê°€ì§ˆ ìˆ˜ ì—†ëŠ” ê²ƒ ì•„ë‹Œê°€?\n",
    "    - x ê°€ $- \\infty $ ì¸ ê²½ìš°ì—ë§Œ 0 ì´ ê°€ëŠ¥í•œë°?\n",
    "  - ë‹µë³€ (GPT)\n",
    "    - ì´ í•¨ìˆ˜ì˜ ì¶œë ¥ ë²”ìœ„ëŠ” (0, 1) (ì¦‰, 0ê³¼ 1ì´ ì ˆëŒ€ ë  ìˆ˜ ì—†ìŒ)\n",
    "    - ê·¸ëŸ¬ë‚˜, y = sigmoid(z)ì—ì„œ zê°€ ë§¤ìš° ì‘ê±°ë‚˜ ë§¤ìš° í´ ë•Œ yê°€ 0 ë˜ëŠ” 1ì— ê·¹ë„ë¡œ ê°€ê¹Œì›Œì§ˆ ìˆ˜ ìˆìŒ\n",
    "    - ì˜ˆë¥¼ ë“¤ì–´:\n",
    "      - z = -1000ì´ë©´ y â‰ˆ 0.0...001 (ê±°ì˜ 0)\n",
    "      - z = 1000ì´ë©´ y â‰ˆ 0.9999...99 (ê±°ì˜ 1)\n",
    "    - ì¦‰, ì´ë¡ ì ìœ¼ë¡œ 0ì´ ë˜ì§€ ì•Šì§€ë§Œ, ì»´í“¨í„°ì˜ ë¶€ë™ì†Œìˆ˜ì (floating point) í‘œí˜„ì—ì„œëŠ” ë§¤ìš° ì‘ì€ ê°’ì´ 0ìœ¼ë¡œ ê°„ì£¼ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "  - ..\n",
    "  - $ L = E(W,b) = - \\sum _{i=1} ^n { \\{\\ t_i log y_i + (1-t_i) log (1-y_i)\\ \\} } $\n",
    "\n",
    "    - ì´ë•Œ:\n",
    "    - ë§Œì•½ y = 0ì´ë¼ë©´, log(0)ì€ **ë§ˆì´ë„ˆìŠ¤ ë¬´í•œëŒ€(-âˆ)**ê°€ ë˜ì–´ ì—ëŸ¬ ë°œìƒ\n",
    "    - ë§Œì•½ y = 1ì´ë¼ë©´, log(1-y) = log(0)ì´ë¯€ë¡œ ì—­ì‹œ ì—ëŸ¬ ë°œìƒ\n",
    "    - ğŸ’¡ ë¶€ë™ì†Œìˆ˜ì  ë¬¸ì œë¡œ ì¸í•´ yê°€ 0 ë˜ëŠ” 1ì— ê·¹ë„ë¡œ ê°€ê¹Œì›Œì§€ëŠ” ê²½ìš°ì—ë„ log(0) ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ!\n",
    "  - ..\n",
    "  - $ L = - \\sum { \\{\\ t log (y + \\delta) + (1-t) log (1-y+\\delta)\\ \\} } $\n",
    "\n",
    "    - ì¤‘ìš”í•œ ì : y ëŒ€ì‹  y + $\\delta$ ë¥¼ ë„£ëŠ”ê²Œ ì•„ë‹ˆê³ , ê·¸ëƒ¥ log() ì•ˆì— $\\delta$ ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒ!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ml_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
